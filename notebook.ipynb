{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import pyworld as pw\n",
    "import parselmouth\n",
    "import argparse\n",
    "import shutil\n",
    "import subprocess\n",
    "import soundfile\n",
    "from logger import utils\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pydub import AudioSegment, effects\n",
    "from ddsp.vocoder import F0_Extractor, Volume_Extractor, Units_Encoder\n",
    "from logger.utils import traverse_dir\n",
    "from preprocess import preprocess\n",
    "from train import ddsp_train\n",
    "from draw import main\n",
    "from sep_wav import demucs, audio_norm, get_ffmpeg_args\n",
    "# Cuda setting\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# configure loading\n",
    "args = utils.load_config('./configs/combsub.yaml')\n",
    "\n",
    "# set path\n",
    "MP4_DATA_PATH   = 'preprocess/mp4'\n",
    "ORIGINAL_PATH   = 'preprocess/original/'\n",
    "DEMUCS_PATH     = 'preprocess/demucs/'\n",
    "NORM_PATH       = 'preprocess/norm/'\n",
    "TEMP_LOG_PATH   = 'temp_ffmpeg_log.txt'  # ffmpeg의 무음 감지 로그의 임시 저장 위치"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.데이터 전처리\n",
    "***\n",
    "1. 난 전처리가 필요없다. 배경음 제거가 완벽하고, 모든 데이터들도 특정 길이로 잘 잘려져있다.\n",
    "    - 데이터를 전부 data/train/audio/안에 다 집어 넣고\n",
    "        ```\n",
    "        # training dataset\n",
    "        data/train/audio/aaa.wav\n",
    "        data/train/audio/bbb.wav\n",
    "        ...\n",
    "        ```\n",
    "    - 1.6 validation 분리단계로 점프\n",
    "***\n",
    "2. 난 거의 다 되어 있지만 데이터가 너무 길다. 특정 길이로 자르고 싶다.\n",
    "    - 데이터를 전부 preprocess/split 안에 다 집어 넣고\n",
    "        ```\n",
    "        # training dataset\n",
    "        preprocess/norm/aaa.wav\n",
    "        preprocess/norm/bbb.wav\n",
    "        ...\n",
    "        ```\n",
    "    - 1.4 split 단계로 점프\n",
    "***\n",
    "3. 난 배경음도 제거해야되고 데이터도 길다. 거의 날 것의 상태다.\n",
    "    - 데이터를 전부 preprocess/original 안에 다 집어넣고\n",
    "        ```\n",
    "        # training dataset\n",
    "        preprocess/original/aaa.wav\n",
    "        preprocess/original/bbb.wav\n",
    "        ...\n",
    "        ```\n",
    "    - 1.2부터 demucs 단계로 점프\n",
    "***\n",
    "4. 난 아무것도 안되어 있고, 심지어 mp4파일이다.\n",
    "    - 데이터들 전부 preprocess/mp4에 다 집어넣고\n",
    "        ```\n",
    "        # training dataset\n",
    "        preprocess/mp4/aaa.mp4\n",
    "        preprocess/mp4/bbb.mp4\n",
    "        ...\n",
    "        ```\n",
    "    - 1.1부터 차례대로 진행"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1데이터가 mp4인 경우 (wav만 있는 경우에는 패스)\n",
    "preprocess/mp4 안에 있는 mp4파일을 wav로 변경 해서 preprocess/original 에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  5.13it/s]\n"
     ]
    }
   ],
   "source": [
    "def mp4_to_wav(input_dir : str, input_file: str, output_dir: str):\n",
    "    \"\"\"mp4파일을 wav형식으로 변환합니다.\n",
    "    Args:\n",
    "        input_dir (str) : 입력 mp4파일의 path\n",
    "        input_file (str) : 입력 mp4파일의 이름\n",
    "        output_dir (str) : 출력 wav파일의 path\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(input_file)[1][1:]\n",
    "\n",
    "    if ext != \"mp4\":\n",
    "        return \n",
    "    else :\n",
    "        track = AudioSegment.from_file(os.path.join(input_dir,input_file),  format= 'mp4')\n",
    "        track = track.set_frame_rate(44100)\n",
    "        track.export(os.path.join(output_dir, input_file[:-4]+\".wav\"), format='wav')\n",
    "\n",
    "\n",
    "filelist =  traverse_dir(\n",
    "    MP4_DATA_PATH,\n",
    "    extension='mp4',\n",
    "    is_pure=True,\n",
    "    is_sort=True,\n",
    "    is_ext=True)\n",
    "\n",
    "for file in tqdm(filelist):\n",
    "    mp4_to_wav(MP4_DATA_PATH, file, ORIGINAL_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 무음제거 (Demucs)\n",
    "preprocess/original에 있는 wav파일들의 음악소리를 제거하고 목소리만 추출해서 preprocess/demucs 에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 03:28:16 | INFO | torchaudio.utils.download | The local file (C:\\Users\\wlsdm\\.cache\\torch\\hub\\torchaudio\\models\\hdemucs_high_trained.pt) exists. Skipping the download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 44100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "목소리 추출 중...: 100%|██████████| 12/12 [00:14<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "demucs(ORIGINAL_PATH, DEMUCS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 normalize\n",
    "preprocess/demucs에 있는 배경음이 제거된 데이터들을 노멀라이즈 해서 preprocess/norm에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "노멀라이징 작업 중...: 100%|██████████| 12/12 [00:07<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for filepath in tqdm(glob(DEMUCS_PATH+\"*.wav\"), desc=\"노멀라이징 작업 중...\"):\n",
    "    filename = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    out_filepath = os.path.join(NORM_PATH, filename) + \".wav\"\n",
    "    audio_norm(filepath, out_filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 split\n",
    "preprocess/norm에 있는 노말라이즈된 데이터들을 15초 길이로 잘라서 data/train/audio에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "음원 자르는 중...: 100%|██████████| 12/12 [00:00<00:00, 14.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for filepath in tqdm(glob(NORM_PATH+\"*.wav\"), desc=\"음원 자르는 중...\"):\n",
    "    duration = librosa.get_duration(filename=filepath)\n",
    "    max_last_seg_duration = 0\n",
    "    sep_duration_final = 15\n",
    "    sep_duration = 15\n",
    "\n",
    "    while sep_duration > 4:\n",
    "        last_seg_duration = duration % sep_duration\n",
    "        if max_last_seg_duration < last_seg_duration:\n",
    "            max_last_seg_duration = last_seg_duration\n",
    "            sep_duration_final = sep_duration\n",
    "        sep_duration -= 1\n",
    "\n",
    "    filename = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    out_filepath = os.path.join(args.data.train_path,\"audio\", f\"{filename}-%04d.wav\")\n",
    "    subprocess.run(f'ffmpeg -i \"{filepath}\" -f segment -segment_time {sep_duration_final} \"{out_filepath}\" -y', capture_output=True, shell=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 무음 제거\n",
    "data/train/audio에 있는 잘라진 음원들 중에 무음인 파일들을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "무음 제거 중...: 100%|██████████| 108/108 [00:04<00:00, 23.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for filepath in tqdm(glob(args.data.train_path+\"/audio/*.wav\"), desc=\"무음 제거 중...\"):\n",
    "    if os.path.exists(TEMP_LOG_PATH):\n",
    "        os.remove(TEMP_LOG_PATH)\n",
    "\n",
    "    ffmpeg_arg = get_ffmpeg_args(filepath)\n",
    "    subprocess.run(ffmpeg_arg, capture_output=True, shell=True)\n",
    "\n",
    "    start = None\n",
    "    end = None\n",
    "\n",
    "    with open(TEMP_LOG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if \"lavfi.silence_start\" in line:\n",
    "                start = float(line.split(\"=\")[1])\n",
    "            if \"lavfi.silence_end\" in line:\n",
    "                end = float(line.split(\"=\")[1])\n",
    "\n",
    "    if start != None:\n",
    "        if start == 0 and end == None:\n",
    "            os.remove(filepath)\n",
    "            \n",
    "if os.path.exists(TEMP_LOG_PATH):\n",
    "        os.remove(TEMP_LOG_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 학습 데이터 중, 일부를 validaion용으로 자동으로 보내준다.\n",
    "- data/train/audio에 있는 데이터 중 일정 비율만큼 알아서 data/val/audio로 이동시켜준다\n",
    "    - 계산식은 다음과 같다 `max(2, min(10, 전체 데이터 * 0.01))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1342.39it/s]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 (학습에 쓰기 위한)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Encoder Model] HuBERT Soft\n",
      " [Loading] pretrain/hubert/hubert-soft-0d54a1f4.pt\n",
      "Preprocess the audio clips in : data/train\\audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:07<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess the audio clips in : data/val\\audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 18.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "sample_rate = args.data.sampling_rate\n",
    "hop_size = args.data.block_size\n",
    "\n",
    "# initialize f0 extractor\n",
    "f0_extractor = F0_Extractor(\n",
    "                    args.data.f0_extractor, \n",
    "                    args.data.sampling_rate, \n",
    "                    args.data.block_size, \n",
    "                    args.data.f0_min, \n",
    "                    args.data.f0_max)\n",
    "\n",
    "# initialize volume extractor\n",
    "volume_extractor = Volume_Extractor(args.data.block_size)\n",
    "                    \n",
    "# initialize units encoder\n",
    "units_encoder = Units_Encoder(\n",
    "                    args.data.encoder, \n",
    "                    args.data.encoder_ckpt, \n",
    "                    args.data.encoder_sample_rate, \n",
    "                    args.data.encoder_hop_size, \n",
    "                    device = device)    \n",
    "\n",
    "# preprocess training set\n",
    "preprocess(args.data.train_path, f0_extractor, volume_extractor, units_encoder, sample_rate, hop_size, device = device)\n",
    "\n",
    "# preprocess validation set\n",
    "preprocess(args.data.valid_path, f0_extractor, volume_extractor, units_encoder, sample_rate, hop_size, device = device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >    exp: exp/combsub-test\n",
      " [DDSP Model] Combtooth Subtractive Synthesiser\n",
      "Load all the data from : data/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:01<00:00, 68.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all the data from : data/val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 64.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- model size ---\n",
      "model: 3,607,302\n",
      "======= start training =======\n",
      "epoch: 1 |   4/  5 | exp/combsub-test | batch/s: 1.81 | loss: 5.229 | time: 0:00:05.5 | step: 10\n",
      "epoch: 3 |   4/  5 | exp/combsub-test | batch/s: 19.93 | loss: 4.447 | time: 0:00:06.0 | step: 20\n",
      "epoch: 5 |   4/  5 | exp/combsub-test | batch/s: 21.93 | loss: 3.440 | time: 0:00:06.4 | step: 30\n",
      "epoch: 7 |   4/  5 | exp/combsub-test | batch/s: 19.60 | loss: 2.462 | time: 0:00:06.9 | step: 40\n",
      "epoch: 9 |   4/  5 | exp/combsub-test | batch/s: 20.63 | loss: 1.844 | time: 0:00:07.4 | step: 50\n",
      "epoch: 11 |   4/  5 | exp/combsub-test | batch/s: 20.95 | loss: 1.560 | time: 0:00:07.9 | step: 60\n",
      "epoch: 13 |   4/  5 | exp/combsub-test | batch/s: 19.49 | loss: 1.124 | time: 0:00:08.4 | step: 70\n",
      "epoch: 15 |   4/  5 | exp/combsub-test | batch/s: 20.87 | loss: 1.168 | time: 0:00:08.9 | step: 80\n",
      "epoch: 17 |   4/  5 | exp/combsub-test | batch/s: 21.53 | loss: 1.092 | time: 0:00:09.3 | step: 90\n",
      "epoch: 19 |   4/  5 | exp/combsub-test | batch/s: 19.72 | loss: 1.201 | time: 0:00:09.9 | step: 100\n",
      "epoch: 21 |   4/  5 | exp/combsub-test | batch/s: 21.81 | loss: 1.112 | time: 0:00:10.3 | step: 110\n",
      "epoch: 23 |   4/  5 | exp/combsub-test | batch/s: 21.17 | loss: 1.084 | time: 0:00:10.8 | step: 120\n",
      "epoch: 25 |   4/  5 | exp/combsub-test | batch/s: 19.30 | loss: 1.195 | time: 0:00:11.3 | step: 130\n",
      "epoch: 27 |   4/  5 | exp/combsub-test | batch/s: 22.30 | loss: 1.117 | time: 0:00:11.8 | step: 140\n",
      "epoch: 29 |   4/  5 | exp/combsub-test | batch/s: 19.73 | loss: 0.996 | time: 0:00:12.3 | step: 150\n",
      "epoch: 31 |   4/  5 | exp/combsub-test | batch/s: 19.64 | loss: 1.117 | time: 0:00:12.8 | step: 160\n",
      "epoch: 33 |   4/  5 | exp/combsub-test | batch/s: 22.50 | loss: 1.200 | time: 0:00:13.2 | step: 170\n",
      "epoch: 35 |   4/  5 | exp/combsub-test | batch/s: 19.93 | loss: 0.979 | time: 0:00:13.7 | step: 180\n",
      "epoch: 37 |   4/  5 | exp/combsub-test | batch/s: 20.01 | loss: 1.002 | time: 0:00:14.2 | step: 190\n",
      "epoch: 39 |   4/  5 | exp/combsub-test | batch/s: 22.42 | loss: 1.070 | time: 0:00:14.7 | step: 200\n",
      "epoch: 41 |   4/  5 | exp/combsub-test | batch/s: 19.90 | loss: 0.983 | time: 0:00:15.2 | step: 210\n",
      "epoch: 43 |   4/  5 | exp/combsub-test | batch/s: 21.08 | loss: 1.043 | time: 0:00:15.6 | step: 220\n",
      "epoch: 45 |   4/  5 | exp/combsub-test | batch/s: 21.06 | loss: 1.032 | time: 0:00:16.1 | step: 230\n",
      "epoch: 47 |   4/  5 | exp/combsub-test | batch/s: 18.20 | loss: 0.995 | time: 0:00:16.7 | step: 240\n",
      "epoch: 49 |   4/  5 | exp/combsub-test | batch/s: 20.74 | loss: 0.970 | time: 0:00:17.1 | step: 250\n",
      "epoch: 51 |   4/  5 | exp/combsub-test | batch/s: 21.31 | loss: 1.011 | time: 0:00:17.6 | step: 260\n",
      "epoch: 53 |   4/  5 | exp/combsub-test | batch/s: 20.22 | loss: 1.009 | time: 0:00:18.1 | step: 270\n",
      "epoch: 55 |   4/  5 | exp/combsub-test | batch/s: 23.33 | loss: 0.989 | time: 0:00:18.5 | step: 280\n",
      "epoch: 57 |   4/  5 | exp/combsub-test | batch/s: 20.19 | loss: 0.962 | time: 0:00:19.0 | step: 290\n",
      "epoch: 59 |   4/  5 | exp/combsub-test | batch/s: 20.24 | loss: 0.919 | time: 0:00:19.5 | step: 300\n",
      "epoch: 61 |   4/  5 | exp/combsub-test | batch/s: 22.60 | loss: 0.950 | time: 0:00:20.0 | step: 310\n",
      "epoch: 63 |   4/  5 | exp/combsub-test | batch/s: 20.11 | loss: 0.964 | time: 0:00:20.5 | step: 320\n",
      "epoch: 65 |   4/  5 | exp/combsub-test | batch/s: 21.04 | loss: 0.945 | time: 0:00:20.9 | step: 330\n",
      "epoch: 67 |   4/  5 | exp/combsub-test | batch/s: 22.88 | loss: 0.956 | time: 0:00:21.4 | step: 340\n",
      "epoch: 69 |   4/  5 | exp/combsub-test | batch/s: 20.11 | loss: 0.998 | time: 0:00:21.9 | step: 350\n",
      "epoch: 71 |   4/  5 | exp/combsub-test | batch/s: 22.19 | loss: 0.896 | time: 0:00:22.3 | step: 360\n",
      "epoch: 73 |   4/  5 | exp/combsub-test | batch/s: 21.44 | loss: 0.956 | time: 0:00:22.8 | step: 370\n",
      "epoch: 75 |   4/  5 | exp/combsub-test | batch/s: 19.42 | loss: 0.927 | time: 0:00:23.3 | step: 380\n",
      "epoch: 77 |   4/  5 | exp/combsub-test | batch/s: 22.03 | loss: 0.895 | time: 0:00:23.8 | step: 390\n",
      "epoch: 79 |   4/  5 | exp/combsub-test | batch/s: 19.66 | loss: 0.961 | time: 0:00:24.3 | step: 400\n",
      "epoch: 81 |   4/  5 | exp/combsub-test | batch/s: 19.86 | loss: 0.922 | time: 0:00:24.8 | step: 410\n",
      "epoch: 83 |   4/  5 | exp/combsub-test | batch/s: 22.91 | loss: 0.898 | time: 0:00:25.2 | step: 420\n",
      "epoch: 85 |   4/  5 | exp/combsub-test | batch/s: 20.25 | loss: 0.914 | time: 0:00:25.7 | step: 430\n",
      "epoch: 87 |   4/  5 | exp/combsub-test | batch/s: 21.08 | loss: 0.946 | time: 0:00:26.2 | step: 440\n",
      "epoch: 89 |   4/  5 | exp/combsub-test | batch/s: 22.10 | loss: 0.928 | time: 0:00:26.6 | step: 450\n",
      "epoch: 91 |   4/  5 | exp/combsub-test | batch/s: 20.40 | loss: 0.906 | time: 0:00:27.1 | step: 460\n",
      "epoch: 93 |   4/  5 | exp/combsub-test | batch/s: 23.33 | loss: 0.933 | time: 0:00:27.6 | step: 470\n",
      "epoch: 95 |   4/  5 | exp/combsub-test | batch/s: 21.22 | loss: 0.924 | time: 0:00:28.0 | step: 480\n",
      "epoch: 97 |   4/  5 | exp/combsub-test | batch/s: 19.93 | loss: 0.899 | time: 0:00:28.5 | step: 490\n",
      "epoch: 99 |   4/  5 | exp/combsub-test | batch/s: 22.13 | loss: 0.932 | time: 0:00:29.0 | step: 500\n",
      "epoch: 101 |   4/  5 | exp/combsub-test | batch/s: 19.92 | loss: 0.906 | time: 0:00:29.5 | step: 510\n",
      "epoch: 103 |   4/  5 | exp/combsub-test | batch/s: 20.52 | loss: 0.983 | time: 0:00:30.0 | step: 520\n",
      "epoch: 105 |   4/  5 | exp/combsub-test | batch/s: 22.45 | loss: 0.910 | time: 0:00:30.4 | step: 530\n",
      "epoch: 107 |   4/  5 | exp/combsub-test | batch/s: 20.24 | loss: 0.920 | time: 0:00:30.9 | step: 540\n",
      "epoch: 109 |   4/  5 | exp/combsub-test | batch/s: 22.78 | loss: 0.873 | time: 0:00:31.4 | step: 550\n",
      "epoch: 111 |   4/  5 | exp/combsub-test | batch/s: 21.79 | loss: 0.905 | time: 0:00:31.8 | step: 560\n",
      "epoch: 113 |   4/  5 | exp/combsub-test | batch/s: 20.36 | loss: 0.909 | time: 0:00:32.3 | step: 570\n",
      "epoch: 115 |   4/  5 | exp/combsub-test | batch/s: 23.63 | loss: 0.916 | time: 0:00:32.7 | step: 580\n",
      "epoch: 117 |   4/  5 | exp/combsub-test | batch/s: 20.07 | loss: 0.885 | time: 0:00:33.2 | step: 590\n",
      "epoch: 119 |   4/  5 | exp/combsub-test | batch/s: 21.53 | loss: 0.907 | time: 0:00:33.7 | step: 600\n",
      "epoch: 121 |   4/  5 | exp/combsub-test | batch/s: 23.04 | loss: 0.979 | time: 0:00:34.1 | step: 610\n",
      "epoch: 123 |   4/  5 | exp/combsub-test | batch/s: 21.04 | loss: 0.877 | time: 0:00:34.6 | step: 620\n",
      "epoch: 125 |   4/  5 | exp/combsub-test | batch/s: 22.98 | loss: 0.892 | time: 0:00:35.0 | step: 630\n",
      "epoch: 127 |   4/  5 | exp/combsub-test | batch/s: 20.67 | loss: 0.897 | time: 0:00:35.5 | step: 640\n",
      "epoch: 129 |   4/  5 | exp/combsub-test | batch/s: 20.71 | loss: 0.915 | time: 0:00:36.0 | step: 650\n",
      "epoch: 131 |   4/  5 | exp/combsub-test | batch/s: 23.41 | loss: 0.864 | time: 0:00:36.4 | step: 660\n",
      "epoch: 133 |   4/  5 | exp/combsub-test | batch/s: 20.59 | loss: 0.886 | time: 0:00:36.9 | step: 670\n",
      "epoch: 135 |   4/  5 | exp/combsub-test | batch/s: 21.84 | loss: 0.903 | time: 0:00:37.4 | step: 680\n",
      "epoch: 137 |   4/  5 | exp/combsub-test | batch/s: 21.94 | loss: 0.882 | time: 0:00:37.8 | step: 690\n",
      "epoch: 139 |   4/  5 | exp/combsub-test | batch/s: 20.52 | loss: 0.862 | time: 0:00:38.3 | step: 700\n",
      "epoch: 141 |   4/  5 | exp/combsub-test | batch/s: 23.44 | loss: 0.865 | time: 0:00:38.7 | step: 710\n",
      "epoch: 143 |   4/  5 | exp/combsub-test | batch/s: 20.11 | loss: 0.938 | time: 0:00:39.2 | step: 720\n",
      "epoch: 145 |   4/  5 | exp/combsub-test | batch/s: 20.61 | loss: 0.875 | time: 0:00:39.7 | step: 730\n",
      "epoch: 147 |   4/  5 | exp/combsub-test | batch/s: 22.65 | loss: 0.863 | time: 0:00:40.2 | step: 740\n",
      "epoch: 149 |   4/  5 | exp/combsub-test | batch/s: 20.30 | loss: 0.867 | time: 0:00:40.6 | step: 750\n",
      "epoch: 151 |   4/  5 | exp/combsub-test | batch/s: 21.49 | loss: 0.882 | time: 0:00:41.1 | step: 760\n",
      "epoch: 153 |   4/  5 | exp/combsub-test | batch/s: 21.93 | loss: 0.872 | time: 0:00:41.6 | step: 770\n",
      "epoch: 155 |   4/  5 | exp/combsub-test | batch/s: 20.89 | loss: 0.888 | time: 0:00:42.0 | step: 780\n",
      "epoch: 157 |   4/  5 | exp/combsub-test | batch/s: 23.28 | loss: 0.860 | time: 0:00:42.5 | step: 790\n",
      "epoch: 159 |   4/  5 | exp/combsub-test | batch/s: 20.74 | loss: 0.866 | time: 0:00:43.0 | step: 800\n",
      "epoch: 161 |   4/  5 | exp/combsub-test | batch/s: 21.40 | loss: 0.875 | time: 0:00:43.4 | step: 810\n",
      "epoch: 163 |   4/  5 | exp/combsub-test | batch/s: 21.98 | loss: 0.889 | time: 0:00:43.9 | step: 820\n",
      "epoch: 165 |   4/  5 | exp/combsub-test | batch/s: 20.63 | loss: 0.924 | time: 0:00:44.4 | step: 830\n",
      "epoch: 167 |   4/  5 | exp/combsub-test | batch/s: 22.47 | loss: 0.870 | time: 0:00:44.8 | step: 840\n",
      "epoch: 169 |   4/  5 | exp/combsub-test | batch/s: 22.22 | loss: 0.890 | time: 0:00:45.3 | step: 850\n",
      "epoch: 171 |   4/  5 | exp/combsub-test | batch/s: 20.17 | loss: 0.923 | time: 0:00:45.8 | step: 860\n",
      "epoch: 173 |   4/  5 | exp/combsub-test | batch/s: 23.94 | loss: 0.893 | time: 0:00:46.2 | step: 870\n",
      "epoch: 175 |   4/  5 | exp/combsub-test | batch/s: 20.71 | loss: 0.891 | time: 0:00:46.7 | step: 880\n",
      "epoch: 177 |   4/  5 | exp/combsub-test | batch/s: 21.22 | loss: 0.854 | time: 0:00:47.1 | step: 890\n",
      "epoch: 179 |   4/  5 | exp/combsub-test | batch/s: 21.63 | loss: 0.853 | time: 0:00:47.6 | step: 900\n",
      "epoch: 181 |   4/  5 | exp/combsub-test | batch/s: 20.86 | loss: 0.856 | time: 0:00:48.1 | step: 910\n",
      "epoch: 183 |   4/  5 | exp/combsub-test | batch/s: 22.93 | loss: 0.846 | time: 0:00:48.5 | step: 920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ddsp_train(args)\n",
      "File \u001b[1;32mc:\\Users\\wlsdm\\project\\DDSP-SVC-KOR\\train.py:156\u001b[0m, in \u001b[0;36mddsp_train\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    153\u001b[0m loader_train, loader_valid \u001b[39m=\u001b[39m get_data_loaders(args, whole_audio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    155\u001b[0m \u001b[39m# run\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m train(args, initial_global_step, model, optimizer, loss_func, loader_train, loader_valid)\n",
      "File \u001b[1;32mc:\\Users\\wlsdm\\project\\DDSP-SVC-KOR\\solver.py:84\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(args, initial_global_step, model, optimizer, loss_func, loader_train, loader_test)\u001b[0m\n\u001b[0;32m     82\u001b[0m saver\u001b[39m.\u001b[39mlog_info(\u001b[39m'\u001b[39m\u001b[39m======= start training =======\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(args\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mepochs):\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader_train):\n\u001b[0;32m     85\u001b[0m         saver\u001b[39m.\u001b[39mglobal_step_increment()\n\u001b[0;32m     86\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\wlsdm\\anaconda3\\envs\\ddsp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\wlsdm\\anaconda3\\envs\\ddsp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wlsdm\\anaconda3\\envs\\ddsp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m   1284\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[1;32m-> 1285\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1286\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1287\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\wlsdm\\anaconda3\\envs\\ddsp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1134\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wlsdm\\anaconda3\\envs\\ddsp\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\wlsdm\\anaconda3\\envs\\ddsp\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddsp_train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
